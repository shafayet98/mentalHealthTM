{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16570b34-70a6-43a2-9abe-5ace3d1f8072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shafayetulislam/Documents/mentalHealthTM/mentalHealthTMenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import spacy as sp\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pyLDAvis.gensim\n",
    "import pyLDAvis\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6e04ec2-f07d-4237-8685-c2dd36ef6f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bb8d24d-7a5a-4f50-9a00-89abf90433d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c04ea9a-03a7-4f34-a86d-c8b783742072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecf766c2-dbb6-4d59-a238-31159ddbd22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the col context fully...\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4cdf143-d7c8-420a-a7e1-0b40fbd73ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"Amod/mental_health_counseling_conversations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc9169f3-7fcd-45da-a5f0-5a0a08b2967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81e444be-8a1d-4c07-85db-d119d0581deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_contexts = df['Context'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb8b0e57-abf6-4761-9b32-291cbe4bc985",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_contexts_list = unique_contexts.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0d80fc6-c8ca-4f32-b554-a9101ac147d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shafayetulislam/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac697580-115c-490f-ab36-54712b62099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_preprocess(text):\n",
    "    \"\"\"\n",
    "    Simple preprocessing function without relying on NLTK\n",
    "    \"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "    \n",
    "    # Split on whitespace\n",
    "    tokens = text.split()\n",
    "    \n",
    "    \n",
    "    # Remove stop words\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c9c1706-fab0-4dd1-9e40-b0b50c006a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_topic_modeling(texts, n_topics=5):\n",
    "    \"\"\"\n",
    "    Perform topic modeling using both LDA and NMF\n",
    "    \"\"\"\n",
    "    # Preprocess texts\n",
    "    processed_texts = [simple_preprocess(text) for text in texts]\n",
    "    \n",
    "    # Create TF-IDF matrix\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=1000,\n",
    "        min_df=2,\n",
    "        max_df=0.95\n",
    "    )\n",
    "    dtm = vectorizer.fit_transform(processed_texts)\n",
    "    \n",
    "    # Perform LDA\n",
    "    lda_model = LatentDirichletAllocation(\n",
    "        n_components=n_topics,\n",
    "        random_state=42,\n",
    "        max_iter=20\n",
    "    )\n",
    "    \n",
    "    # Fit LDA model\n",
    "    doc_topics = lda_model.fit_transform(dtm)\n",
    "    \n",
    "    # Get feature names\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    # Get top words for each topic\n",
    "    n_top_words = 10\n",
    "    topics = []\n",
    "    for topic_idx, topic in enumerate(lda_model.components_):\n",
    "        top_words = [feature_names[i] for i in topic.argsort()[:-n_top_words-1:-1]]\n",
    "        topics.append({\n",
    "            'topic_id': topic_idx,\n",
    "            'words': top_words\n",
    "        })\n",
    "    \n",
    "    # Create dictionary and corpus\n",
    "    dictionary = Dictionary(processed_texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in processed_texts]\n",
    "\n",
    "    visualize_interactive_lda(lda_model, corpus, dictionary)\n",
    "    \n",
    "    return {\n",
    "        'doc_topics': doc_topics,\n",
    "        'topics': topics,\n",
    "        'model': lda_model,\n",
    "        'vectorizer': vectorizer,\n",
    "        'processed_texts': processed_texts\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ab74d1-9bab-4c31-9122-4b78066d8df6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55fa969f-1d20-4b75-a083-c8faa5a2c8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with your data\n",
    "def analyze_mental_health_topics(text_list):\n",
    "    \"\"\"\n",
    "    Analyze mental health conversations and print topics\n",
    "    \"\"\"\n",
    "    print(\"Starting analysis...\")\n",
    "    results = perform_topic_modeling(text_list, n_topics=10)\n",
    "    \n",
    "    print(\"\\nDiscovered Topics:\")\n",
    "    for topic in results['topics']:\n",
    "        print(f\"\\nTopic {topic['topic_id'] + 1}:\")\n",
    "        print(\", \".join(topic['words']))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d95d26b-41b0-4f27-a4f7-b2c45bd1cbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis...\n",
      "\n",
      "Discovered Topics:\n",
      "\n",
      "Topic 1:\n",
      "men, voices, therapy, abuse, remember, dealing, shake, learn, enough, far\n",
      "\n",
      "Topic 2:\n",
      "ask, drinking, see, lonely, daughter, husband, doctor, talking, pictures, second\n",
      "\n",
      "Topic 3:\n",
      "like, feel, want, always, know, time, never, things, really, talk\n",
      "\n",
      "Topic 4:\n",
      "done, depressed, thinks, act, attracted, dependent, causing, type, angry, concerned\n",
      "\n",
      "Topic 5:\n",
      "sexual, job, says, worker, fall, counseling, social, help, past, co\n",
      "\n",
      "Topic 6:\n",
      "depression, anxiety, names, help, stress, counseling, deal, mood, doctor, violent\n",
      "\n",
      "Topic 7:\n",
      "feel, like, get, want, know, years, love, time, relationship, think\n",
      "\n",
      "Topic 8:\n",
      "counselor, child, fight, wife, mother, lazy, client, parent, chance, sad\n",
      "\n",
      "Topic 9:\n",
      "difficult, feel, listen, order, trust, cannot, age, listening, approach, seems\n",
      "\n",
      "Topic 10:\n",
      "disorder, therapist, brother, friends, understand, two, gets, really, family, never\n"
     ]
    }
   ],
   "source": [
    "results = analyze_mental_health_topics(unique_contexts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d38673-aa51-4f7a-b0d8-faa2195e0c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming you have your LDA model, corpus, and dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d91ff5e-06d5-48d9-bb3e-fed5e52a6c6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processed_texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpora\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dictionary\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Create dictionary and corpus\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m dictionary \u001b[38;5;241m=\u001b[39m Dictionary(\u001b[43mprocessed_texts\u001b[49m)\n\u001b[1;32m      5\u001b[0m corpus \u001b[38;5;241m=\u001b[39m [dictionary\u001b[38;5;241m.\u001b[39mdoc2bow(text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m processed_texts]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Visualize with pyLDAvis\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'processed_texts' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Visualize with pyLDAvis\n",
    "visualize_interactive_lda(lda_model, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941a767e-3abc-48a7-8892-1aa786b99669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efda761-2000-4f7e-af32-9dea3d638262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ff2d6e-5954-4502-a576-569fed47106c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0144b50a-f616-4d35-9c4d-af0adab67ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc92d24b-ff31-4c5e-8bd8-035df36b54fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee2c053-f7e5-4654-8b78-02eba06da8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a6348a-6d85-4949-a4ff-eb2ba1a849e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2791b9d-d976-48fd-97f4-ec953788df13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a502aa-f72b-4216-b7e1-0367746b2634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0fbf21-479e-483f-b9c5-fa62d255b541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2f255a-b447-470d-8b41-7a3341b7d98c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1103314c-468f-4bf9-8a94-707e1a113367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d849c483-8592-4fd8-b568-0eaecc556aea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfb52e4-f8ec-4440-926b-55f172654d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cb142a-26e1-4e3c-b6bd-8d5bb2bb65f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b0ec6d-33b0-4406-80f4-7beba0fde42e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b79ad8-26bd-4685-b577-76bf473c4c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb54ffcb-c3ed-4177-a08e-8c11a7fd4a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fed450-869a-4a3b-9044-270235db25e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f734839-6e34-405f-9e56-68ee18021870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f9ea63-4904-4b9a-a13b-60277fe5c97c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382a588c-c935-4f96-bea8-47d5c5cb28e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09757269-910e-4950-85d9-fe7657c5be60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
